import os
import random

import hydra
import numpy as np
import torch
import torch.nn as nn
from omegaconf import DictConfig
from torch.distributions.categorical import Categorical
from torch_geometric.utils import to_dense_adj, to_dense_batch

from great.dataset.data_object import get_data_object
from great.decoding.tsp_decoder import DecoderForLarge
from great.envs.tsp_env import MultiTrajectoryTSP
from great.models.great import GREATEncoder
from great.utils.constants import BENCHMARKING_RL_CONFIGS_PATH, FIGURE_PATH
from great.utils.tour_wrapper import get_lkh_results_dists
from great.utils.utils import (
    get_all_trained_models_configs,
    get_matching_config,
    get_model_file,
    set_hyperparams,
    set_seeds,
)

"""This script is to visualize the similarity of node feature vectors generated by a trained GREAT RL model that are then passed on to the decoder"""


class GREATRL_TSP(nn.Module):
    """
    THis class is a copy from the GREATRL_TSP in the great.models.tsp_model.py, but it has an additional keyword in the get_tour to return the embeddings so we can visualize them
    """

    def __init__(
        self,
        initial_dim,
        hidden_dim,
        num_layers,
        num_nodes,
        heads,
        group_size=20,
        final_node_layer=True,
        nodeless=False,
        asymmetric=False,
        dropout=0.1,
    ):
        super(GREATRL_TSP, self).__init__()
        assert (
            hidden_dim % heads == 0
        ), "hidden_dimension must be divisible by the number of heads such that the dimension of the concatenation is equal to hidden_dim again"

        self.encoder = GREATEncoder(
            initial_dim=initial_dim,
            hidden_dim=hidden_dim,
            num_layers=num_layers,
            num_nodes=num_nodes,
            heads=heads,
            final_node_layer=final_node_layer,
            nodeless=nodeless,
            asymmetric=asymmetric,
            dropout=dropout,
        )
        self.decoder = DecoderForLarge(
            embedding_dim=hidden_dim,
            n_heads=8,
            tanh_clipping=50,
            multi_pointer=8,
            multi_pointer_level=1,
            add_more_query=True,
        )
        self.group_size = group_size
        self.final_node_layer = final_node_layer

    def forward(self, data, return_length=False, augmentation_factor=1):
        factor = 1.0
        if augmentation_factor > 1:
            step_size = 0.5 / (augmentation_factor // 2)

            possible_factors = [1]
            possible_factors.extend(
                [0.5 + x * step_size for x in range(augmentation_factor // 2)]
            )
            possible_factors.extend(
                [1.5 - x * step_size for x in range(augmentation_factor // 2)]
            )  ## 0.5 ... 1 ... 1.5
            factor = random.choice(possible_factors)

            if data.edge_attr.dim() == 2:
                data.edge_attr[:, 0] = data.edge_attr[:, 0] * factor
            else:  # only 1D
                data.edge_attr = data.edge_attr * factor

        embeddings = self.encoder(data)

        embeddings, _ = to_dense_batch(embeddings, data.batch)
        if data.edge_attr.dim() == 2:  # augmented edge attributes
            dists = to_dense_adj(data.edge_index, data.batch, data.edge_attr)[
                :, :, :, 0
            ]
        else:  # only 1D attributes
            dists = to_dense_adj(data.edge_index, data.batch, data.edge_attr)

        B, N, H = embeddings.shape
        G = self.group_size

        batch_idx_range = torch.arange(B)[:, None].expand(B, G)
        group_idx_range = torch.arange(G)[None, :].expand(B, G)

        env = MultiTrajectoryTSP(dists.cpu())
        s, r, d = env.reset(group_size=G)

        # self.decoder.reset(batch.x.view(B, N, new_node_dim), embeddings, G)
        self.decoder.reset(dists, embeddings, G)

        entropy_list = []
        log_prob = torch.zeros(B, G, device=embeddings.device)
        while not d:
            if s.current_node is None:
                first_action = torch.randperm(N)[None, :G].expand(B, G)
                s, r, d = env.step(first_action)
                continue
            else:
                last_node = s.current_node

            action_probs = self.decoder(
                last_node.to(embeddings.device),
                s.ninf_mask.to(embeddings.device),
                s.selected_count,
            )
            m = Categorical(action_probs.reshape(B * G, -1))
            entropy_list.append(m.entropy().mean().item())
            action = m.sample().view(B, G)
            chosen_action_prob = (
                action_probs[batch_idx_range, group_idx_range, action].reshape(B, G)
                + 1e-8
            )
            log_prob += chosen_action_prob.log()
            s, r, d = env.step(action.cpu())

        r_trans = r.to(embeddings.device)

        advantage = (
            (r_trans - r_trans.mean(dim=1, keepdim=True))
            / (r_trans.std(dim=1, unbiased=False, keepdim=True) + 1e-8)
            if G != 1
            else r_trans
        )

        loss = (-advantage * log_prob).mean()

        if return_length:
            length_max = -r.max(dim=1)[0].mean().clone().detach().item()
            length_max = length_max / factor  # renormalize distance by factor
            return loss, length_max

        return loss

    def get_tour(self, data, augmentation_factor=1, return_nodes=False):
        embedding_list = []
        dists_list = []

        if augmentation_factor > 1:
            step_size = 0.5 / (augmentation_factor // 2)
        possible_factors = [1]
        possible_factors.extend(
            [0.5 + x * step_size for x in range(augmentation_factor // 2)]
        )
        possible_factors.extend(
            [1.5 - x * step_size for x in range(augmentation_factor // 2)]
        )  ## 0.9 ... 1 ... 1.1
        augmentation_factor = len(possible_factors)  # might be increased by 1
        if data.edge_attr.dim() == 2:
            orig_dist = data.edge_attr[:, 0].detach().clone()
        else:
            orig_dist = data.edge_attr.detach().clone()

        for f in possible_factors:
            if data.edge_attr.dim() == 2:
                data.edge_attr[:, 0] = orig_dist * f
            else:  # only 1D
                data.edge_attr = orig_dist * f

            embeddings = self.encoder(data)

            if return_nodes:
                return embeddings

            embeddings, _ = to_dense_batch(embeddings, data.batch)
            if data.edge_attr.dim() == 2:  # augmented edge attributes
                dists = to_dense_adj(data.edge_index, data.batch, data.edge_attr)[
                    :, :, :, 0
                ]
            else:  # only 1D attributes
                dists = to_dense_adj(data.edge_index, data.batch, data.edge_attr)
            embedding_list.append(embeddings)
            dists_list.append(dists)

        embeddings = torch.cat(embedding_list, dim=0)
        dists = torch.cat(dists_list, dim=0)

        B, N, H = embeddings.shape
        G = 30

        env = MultiTrajectoryTSP(dists.cpu())
        s, r, d = env.reset(group_size=G)

        # self.decoder.reset(batch.x.view(B, N, new_node_dim), embeddings, G)
        self.decoder.reset(dists, embeddings, G)

        first_action = torch.randperm(N)[None, :G].expand(B, G)
        pi = first_action[..., None].to(embeddings.device)
        s, r, d = env.step(first_action)

        while not d:
            action_probs = self.decoder(
                s.current_node.to(embeddings.device),
                s.ninf_mask.to(embeddings.device),
                s.selected_count,
            )
            action = action_probs.argmax(dim=2)
            pi = torch.cat([pi, action[..., None]], dim=-1)
            s, r, d = env.step(action.cpu())

        B = round(B / augmentation_factor)
        reward = r.reshape(augmentation_factor, B, G)
        pi = pi.reshape(augmentation_factor, B, G, N)

        coefficients = torch.tensor(possible_factors).view(-1, 1, 1)
        reward = reward / coefficients

        max_reward_aug_ntraj, idx_dim_2 = reward.max(dim=2)
        max_reward_aug_ntraj, idx_dim_0 = max_reward_aug_ntraj.max(dim=0)

        idx_dim_0 = idx_dim_0.to(pi.device)
        idx_dim_2 = idx_dim_2.to(pi.device)

        idx_dim_0 = idx_dim_0.reshape(1, B, 1, 1)
        idx_dim_2 = idx_dim_2.reshape(augmentation_factor, B, 1, 1).gather(0, idx_dim_0)
        best_pi_aug_ntraj = pi.gather(0, idx_dim_0.repeat(1, 1, G, N))
        best_pi_aug_ntraj = best_pi_aug_ntraj.gather(
            2, idx_dim_2.repeat(1, 1, 1, N)
        ).squeeze()

        return -max_reward_aug_ntraj.mean().clone().detach().item(), best_pi_aug_ntraj


def get_vis_model(params):
    model = GREATRL_TSP(
        initial_dim=5,
        hidden_dim=params["hidden_dim"],
        heads=params["heads"],
        num_layers=params["num_layers"],
        num_nodes=params["instance_size"],
        group_size=params["instance_size"],
        final_node_layer=params["final_node_layer"],
        nodeless=params["nodeless"],
        asymmetric=params["asymmetric"],
    )
    return model


@hydra.main(
    version_base=None,
    config_path=BENCHMARKING_RL_CONFIGS_PATH,
    config_name="EUC_TSP_NB",
)
def visualize(cfg: DictConfig):
    ### setting seeds
    set_seeds(1234)

    ### set hyperparameters
    params = set_hyperparams(cfg)
    assert params["task"] == "RL"

    # get the config that matched a model that has been trained already and get its time_stamp (corresponds to an ID)
    configs = get_all_trained_models_configs()
    conf = get_matching_config(configs, params)
    model_time_stamp = conf["timestamp"]
    print(f"Evaluating trained model with timestamp: {model_time_stamp}")

    # get the file where the model with the matching ID is stored and load it
    model_file = get_model_file(model_time_stamp)

    ### init model
    model = get_vis_model(params)
    model.to(params["device"])  # move to device
    model.eval()
    model.load_state_dict(torch.load(model_file, map_location=params["device"]))

    sizes_to_consider = [30, 50, 100]

    for size in sizes_to_consider:
        # get data instance
        np.random.seed(sum(ord(c) for c in "chalmers"))
        coordinates = np.random.rand(size, 2)
        obj = get_data_object(coordinates, False, False)

        # get the node embeddings generated by the encoder of the model
        with torch.no_grad():
            node_embeddings = model.get_tour(
                obj, augmentation_factor=1, return_nodes=True
            )

        if obj.edge_attr.dim() == 2:  # augmented edge attributes
            d = to_dense_adj(obj.edge_index, obj.batch, obj.edge_attr)[:, :, :, 0]
        else:  # only 1D attributes
            d = to_dense_adj(obj.edge_index, obj.batch, obj.edge_attr)
        dists = d.cpu().numpy()

        tour = get_lkh_results_dists(dists[0], not params["asymmetric"])

        vectors = np.array(node_embeddings.tolist())
        num_vectors = vectors.shape[0]

        import matplotlib.patches as patches
        import matplotlib.pyplot as plt

        # Initialize the distance matrix
        distance_matrix = np.zeros((num_vectors, num_vectors))

        # Compute pairwise Euclidean distances
        for i in range(num_vectors):
            for j in range(i, num_vectors):
                dot_product = np.dot(vectors[i], vectors[j])
                norm_A = np.linalg.norm(vectors[i])
                norm_B = np.linalg.norm(vectors[j])
                distance = round(dot_product / (norm_A * norm_B), 2)
                distance_matrix[i, j] = distance
                distance_matrix[j, i] = distance  # Distance is symmetric

        plt.figure(figsize=(12, 9))
        plt.imshow(distance_matrix, cmap="viridis", interpolation="nearest")

        # Add color bar
        plt.colorbar()

        # Add titles and labels
        plt.title("Cosine similarity between node embeddings")
        plt.xlabel("Node")
        plt.ylabel("Node")

        highlight_matrix = np.zeros((size, size))

        for i in range(size - 1):
            highlight_matrix[tour[i], tour[i + 1]] = 1
            highlight_matrix[tour[i + 1], tour[i]] = 1

        highlight_matrix[tour[0], tour[size - 1]] = 1
        highlight_matrix[tour[size - 1], tour[0]] = 1

        rows, cols = highlight_matrix.shape
        for i in range(rows):
            for j in range(cols):
                if highlight_matrix[i, j] == 1:
                    # Draw a rectangle around the tile
                    rect = patches.Rectangle(
                        (j - 0.5, i - 0.5),
                        1,
                        1,
                        linewidth=2,
                        edgecolor="red",
                        facecolor="none",
                    )
                    plt.gca().add_patch(rect)

        # Show the plot
        plt.savefig(
            os.path.join(FIGURE_PATH, "cosine_sim_" + str(size) + ".png"),
            dpi=500,
            bbox_inches="tight",
            pad_inches=0,
        )
        plt.clf()

        # Initialize the distance matrix
        distance_matrix = np.zeros((num_vectors, num_vectors))

        # Compute pairwise Euclidean distances
        for i in range(num_vectors):
            for j in range(i, num_vectors):
                # Compute the Euclidean distance
                distance = round(np.linalg.norm(vectors[i] - vectors[j]), 2)
                distance_matrix[i, j] = distance
                distance_matrix[j, i] = distance  # Distance is symmetric

        plt.figure(figsize=(12, 9))
        plt.imshow(distance_matrix, cmap="viridis", interpolation="nearest")

        # Add color bar
        plt.colorbar()

        # Add titles and labels
        plt.title("Euclidean distances between node embeddings")
        plt.xlabel("Node")
        plt.ylabel("Node")

        highlight_matrix = np.zeros((size, size))

        for i in range(size - 1):
            highlight_matrix[tour[i], tour[i + 1]] = 1
            highlight_matrix[tour[i + 1], tour[i]] = 1

        highlight_matrix[tour[0], tour[size - 1]] = 1
        highlight_matrix[tour[size - 1], tour[0]] = 1

        rows, cols = highlight_matrix.shape
        for i in range(rows):
            for j in range(cols):
                if highlight_matrix[i, j] == 1:
                    # Draw a rectangle around the tile
                    rect = patches.Rectangle(
                        (j - 0.5, i - 0.5),
                        1,
                        1,
                        linewidth=2,
                        edgecolor="red",
                        facecolor="none",
                    )
                    plt.gca().add_patch(rect)

        # Show the plot
        plt.savefig(
            os.path.join(FIGURE_PATH, "euc_dist_" + str(size) + ".png"),
            dpi=500,
            bbox_inches="tight",
            pad_inches=0,
        )
        plt.clf()


if __name__ == "__main__":
    visualize()
